# 8.3 分布式计算框架MapReduce

​		Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架；

​		Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。MapReduce的基本原理是将一个复杂的问题（数据集）分成若干个简单的子问题（数据块）进行解决（map函数）；然后对子问题进行合并（Reduce函数），得到 原有问题的解（结果）。

## 8.3.1 MapReduce编程模式

1. ### MapReduce编程模型简介

   ​	用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)

   1）Mapper阶段

   （1）用户自定义的Mapper要继承自己的父类；

   （2）Mapper的输入数据是<K,V>对的形式；

   （3）Mapper中的业务逻辑写在map()方法中；

   （4）Mapper的输出数据是<K,V>对的形式（<K,V>的类型可自定义）；

   （5）map()方法（maptask进程）对每一个<K,V>调用一次；

   2）Reducer阶段

   （1）用户自定义的Reducer要继承自己的父类；

   （2）Reducer的输入数据类型对应Mapper的输出数据类型，也是<K,V>；

   （3）Reducer的业务逻辑写在reduce()方法中；

   （4）Reducetask进程对每一组相同k的<K,V>组调用一次reduce()方法；

   map()函数处理过后的数据会作为reduce()的输入，最后得出结果。最后写入HDFS中。

   3）Driver阶段

   ​	整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象。

   ## 8.3.2 MapReduce数据流

   在 MapReduce 中，数据是一步一步从 Mapper 流向 Reducer。

   Mapper处理的是<k,v>形式的数据，即不能直接处理文件流，

   1.InputFormat定义了如何拆分和读取这些输入文件。它选择用于输入的文件或其他对象。

   2.Map过程

   ​	Mapper接收<key, Vlaue>形式的数据，并处理成<key,Value>形式的数据，具体的处理过程可有用户自定义。

   3.Combiner过程

   ​		每个map()都可能会产生大量的本地输出，Combiner()的作用就是对Map()就是Map()端的传输出先做一次合并，以减少在Ma()和reduce（）节点之间的数据传输量提高网络I/O性能，是MapReduce的一种优化手段之一。

   4.shuffle过程

   ​		shuffle过程是指从Mapper产生传输出结果，经过一些列的处理，成为最终的reducer直接输入数据为止的整个过程，该过程也是MapReduce的核心过程。shuffle整个过程分为两个阶段，mapper段的shuffle和ruducer端的shuffle。

   5.Reduce过程

   ​		reducer接收<k,,{v,list}>形式的数据流，形成<k,v>形式的数据流输出，输出数据直接写入HDFS，具体的处理过程可有用户定义。在Wordcount中，reducer会将相同key的value list进行累加，得到这个单词出现的总次数，然后输出。

   ## 8.3.3 MapReduce任务运行流程

   ​		MRv2是Hadoop2中的MapReduce任务运行流程。在MRv2中,MapReduce运行时环境由Yarn提供，所以需要MapReduce相关服务和Yarn相关服务进行协同工作，下面先讲述MRv2和Yarn的基本组成，再简述MapReduce任务的执行流程。

   ### 1.MRv2基本组成

   ​		MRv2舍弃了MRv1(是Hadoop1中的MapReduce任务运行流程)中的JobTrack和TaskTrack,而采用一种新的MRAppMaster进行单一任务管理,并与Yam中的Resource Manager和NodeManage协同调度与控制任务,避免了由单一服务(MRv1中的JobTrack)管理和调度所有任务而产生的负载过重的问题。MRv2基本组成如下。
   ​		1)客户端(client):客户端用于向Yarn集群提交任务,是MapReduce用户和Yan集群通信的唯一途径,它通过ApplicationClientProtocol协议(RPC协议的一个实现)与Yarn的ResourceManager通信，通过客户端，还可以对任务状态进行查询或杀死任务等。客户端还可以通过MRClientProtocol协议(RPC协议的一个实现)与MRAppMaster(请看下一条)进行通信，从而直接监控和控制作业，以减轻ResourceManager的负担。
   ​		2)MRAppMaster:MRAppMaster为ApplicationMaster的一个实现,它监控和调度一整套MR任务流程,每个MR任务只产生一个MRAppMaster。MRAppMaster只负责任务管理,并不负责资源的调配。
   ​		3) Map Task和Reduce Task:用户定义的Map函数和Reduce函数的实例化,在MRv2中,它们只能运行在Yam给定的资源限制下,由MRAppMaster和NodeManage协同管理和调度。

   ### 2.Yarn基本组成

   ​		Yarn是一个资源管理平台，它监控和调度整个集群资源，并负责管理集群所有任务的运行和任务资源的分配，它的基本组成如下。

   ​		1) Resource Manager(RM):运行于NameNode,为整个集群的资源调度器,它主要包括两个组件:Resource Schedule(资源调度器)和Applications Manager(应用程序管理器)。
   ​		●Resource Schedule:当有应用程序已经注册需要运行时,ApplicationMaster会向它申请资源，而它会根据当时的资源和限制进行资源分配，它会产生一个container资源描述(第4点)。
   ​		●Applications Manager：它负责管理整个集群运行的所有任务，包括应用程序的提交，和Resource Schedule协商启动和监控ApplicationMaster,并在ApplicationMaster任务失败时在其他结点重启它。
   ​		2)NodeManager:运行于DataNode,监控并管理单个结点的计算资源,并定时向RM汇报结点的资源使用情况，在结点上有任务时，还负责对container进行创建、运行状态的监控及最终销毁。
   ​		3)ApplicationMaster(AM):负责对一个任务流程的调度、管理,包括任务注册、资源申请、以及和NodeManage通信以开启和杀掉任务等。
   ​		4) container：Yam架构下对运算资源的一种描述，它封装了某个结点的多维度资源，包括CPU、RAM、Disk、Network等。当.AM向RM申请资源时,RM分配的资源就是以container表示的, Map task和Reduce Task只能在所分配的container描述限制中运行。

   ### 3.任务流程

   ​		在Yam中,资源管理由ResourceManage和NodeManager共同完成,其中, Resource-Manager中的调度器负责资源的分配,NodeManager负责资源的供给和隔离。Resource-Manager将某个NodeManager上资源分配给任务(所谓的“资源调度”)后,NodeManager需按照要求为任务提供相应的资源，并保证这些资源具有独占性，为任务运行提供基础的保证(所谓的资源隔离)。
   Yarn架构中的MapReduce任务运行流程主要可以分为两个部分：一个是客户端向ResourceManager提交任务,ResourceManager通知相应的NodeManager启动MRAppMaster; 二是MRAppMaster启动成功后，则由它调度整个任务的运行，直到任务完成，其详细步骤如图8-14所示。
   ![img](file:///E:\下载\OneDrive\文档\Tencent Files\3230991671\Image\C2C\15D6E4282599AFB356F33226FA4BF78C.jpg)
   ​		1) client向ResourceManager提交任务。
   ​		2)ResourceManager分配该任务的第一个container,并通知相应的NodeManager启动MRAppMaster。
   ​		3)NodeManager接收命令后,开辟一个container资源空间,并在container中启动相应的MRAppMaster。
   ​		4)MRAppMaster启动之后,第一步会向ResourceManager注册,这样用户可以直接通过MRAppMaster监控任务的运行状态;之后则直接由MRAppMaster调度任务运行,重复5)~8)，直到任务结束。
   ​		5)MRAppMaster以轮询的方式向ResourceManager申请任务运行所需的资源。
   ​		6)一旦ResourceManager配给了资源,MRAppMaster便会与相应的NodeManager通信, 让它划分Container并启动相应的任务(MapTask或ReduceTask)。
   ​		7)NodeManager准备好运行环境,启动任务。
   ​		8)各任务运行，并定时通过RPC协议向MRAppMaster汇报自己的运行状态和进度。MRAppMaster也会实时地监控任务的运行，当发现某个Task假死或失败时，便杀死它重新启动任务。
   ​		9)任务完成,MRAppMaster向ResourceManager通信,注销并关闭自己。